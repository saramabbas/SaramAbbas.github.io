---
layout: splash
title: "Saram Abbas"
permalink: /
header:
  overlay_color: "#000"
  overlay_filter: "0.0"
  overlay_image: /assets/images/banner-image.png
  actions:
    - label: "View Publications"
      url: "/publications/"
    - label: "See Projects"
      url: "/projects/"
excerpt: >
  PhD Researcher in Explainable AI for Oncology — Bridging Clinical Practice with Transparent Machine Learning
---


<div style="display: flex; flex-wrap: wrap; gap: 2rem; margin-top: 2rem; align-items: flex-start;">
<!-- 
  <div style="flex: 1; min-width: 300px;">
    <p>
      Welcome! I'm <strong>Saram Abbas</strong>, a PhD researcher at Newcastle University using interpretable machine learning to improve how we predict cancer recurrence, especially in real-world clinical settings.
      My research focuses on developing transparent models like attention-enhanced neural networks, XGBoost hybrids, and neuro-symbolic AI to bring clarity to complex predictions.
    </p>

    <p>
      I'm particularly passionate about <strong>making AI explainable for clinicians</strong> and <strong>scalable for underserved healthcare systems</strong>.
      My work has been published in <em>Frontiers in Oncology</em> and accepted at <em>EMBC 2025</em>.
    </p>

    <p>
      Feel free to explore my <a href="/publications/">publications</a>, <a href="/projects/">projects</a>,
      or connect via <a href="https://github.com/saramabbas">GitHub</a> or <a href="https://www.linkedin.com/in/saram-abbas/">LinkedIn</a>.
    </p>
  </div> -->



  <div style="flex: 1; min-width: 300px;">
  <p>
    I’m <strong>Saram Abbas</strong> — a PhD researcher at Newcastle University building AI that works with clinicians. My work bridges cutting-edge machine learning with real-world oncology, helping doctors make sense of complex data when lives are on the line.
  </p>

  <p>
    I specialise in interpretable models for predicting bladder cancer recurrence — combining attention mechanisms, XGBoost hybrids, and neuro-symbolic reasoning to deliver clarity, not just accuracy.
  </p>

  <p>
    Whether it’s in a peer-reviewed journal like <em>Frontiers in Oncology</em> or on the ground with NHS datasets, my goal is the same: AI that explains itself — and works for everyone.
  </p>

  <p>
    You’re welcome to browse my <a href="/publications/">publications</a>, check out <a href="/projects/">what I’m building</a>, or connect via <a href="https://github.com/saramabbas">GitHub</a> and <a href="https://www.linkedin.com/in/saram-abbas/">LinkedIn</a>.
  </p>
</div>


<div style="flex: 1; min-width: 300px;">
  <figure style="margin: 0;">
    <img src="/assets/images/AttentionExplanation.png" 
         alt="Attention visual" 
         style="width: 100%; border-radius: 0px; box-shadow: 0 4px 12px rgba(0,0,0,0);">
    <figcaption style="font-family: 'Segoe UI', sans-serif; font-size: 0.7rem; color: #666; margin-top: 0.5rem; text-align: center;">
      Example of the clinician-facing AI tools I'm developing — combining attention heatmaps with clear, patient-specific explanations for bladder cancer recurrence.
    </figcaption>
  </figure>
</div>


</div>

